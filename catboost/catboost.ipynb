{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673426a4",
   "metadata": {},
   "source": [
    "## Main class from main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ae0e2-eab8-4032-9c67-4e2fd2385496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "class CNNClass():\n",
    "    def __init__(self, model, transform, params, name,\n",
    "                 path = 'data/full',\n",
    "                 criterion = nn.CrossEntropyLoss(), \n",
    "                 optimizer = None,\n",
    "                 device = 'cuda',\n",
    "                 lr = 0.001):\n",
    "        \n",
    "        self.model = model\n",
    "        self.transform = transform\n",
    "        \n",
    "        train_data = ImageFolder(f'{path}/train', transform=transform)\n",
    "        valid_data = ImageFolder(f'{path}/valid', transform=transform)\n",
    "        \n",
    "        self.train_loader = DataLoader(train_data, batch_size=params['BATCH_SIZE'], shuffle=True, num_workers=2)\n",
    "        self.valid_loader = DataLoader(valid_data, batch_size=params['BATCH_SIZE'], shuffle=True, num_workers=2)\n",
    "        self.params = params\n",
    "        self.name = name\n",
    "        \n",
    "        if not os.path.exists(f'weights/{self.name}'):\n",
    "            os.mkdir(f'weights/{self.name}')\n",
    "\n",
    "        self.criterion = criterion\n",
    "        if optimizer == None:\n",
    "            self.optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def test(self, path='data/full/test', debug=False):\n",
    "        test_data = ImageFolder(path, transform=self.transform)\n",
    "        test_loader = DataLoader(test_data, batch_size=self.params['BATCH_SIZE'], shuffle=True, num_workers=2)\n",
    "\n",
    "        self.model.load_state_dict(torch.load(f'weights/{self.name}/{self.name}.pth', \n",
    "                                              map_location=self.device)['model'])\n",
    "        self.optimizer.load_state_dict(torch.load(f'weights/{self.name}/{self.name}.pth',\n",
    "                                                  map_location=self.device)['optimizer'])\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82160398-9b29-4320-8f33-3dc2e7c090dd",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Custom class for ImageForlder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612cac80-a6de-4a5e-b695-4414fb2b1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]        \n",
    "        return (img, label ,path)\n",
    "    \n",
    "test_data = ImageFolderWithPaths('data/full/test', transform=transform_sample)\n",
    "test_loader = DataLoader(test_data, batch_size=1)\n",
    "\n",
    "train_data = ImageFolderWithPaths('data/full/train', transform=transform_sample)\n",
    "train_loader = DataLoader(train_data, batch_size=1)\n",
    "\n",
    "valid_data = ImageFolderWithPaths('data/full/valid', transform=transform_sample)\n",
    "valid_loader = DataLoader(valid_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0464c15-c9fc-40b0-8fd5-140d422ddf96",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Save labels and features from different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44442553-b0d5-412c-8e59-deae57c5c541",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68faaa61-ab78-4fa2-984b-9de2c6d74ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "\n",
    "device_sample = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = AlexNet_Weights.DEFAULT\n",
    "model_sample = alexnet(weights=weights)\n",
    "\n",
    "for param in model_sample.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_sample.classifier[-1] = nn.Linear(model_sample.classifier[-1].in_features,\n",
    "                                        100)\n",
    "model_sample.to(device_sample)\n",
    "\n",
    "transform_sample = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model_params = {'BATCH_SIZE': 32,\n",
    "                'EPOCHS': 50,\n",
    "                'EARLY_STOP': 5}\n",
    "\n",
    "model1 = CNNClass(model=model_sample,\n",
    "                  transform=transform_sample,\n",
    "                  params=model_params,\n",
    "                  name='alexnet_native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825424b-dd0e-4f9c-9413-c3d4291d7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.model.load_state_dict(torch.load(f'weights/{model1.name}/{model1.name}.pth', \n",
    "                                        map_location='cpu')['model'])\n",
    "model1.optimizer.load_state_dict(torch.load(f'weights/{model1.name}/{model1.name}.pth',\n",
    "                                            map_location='cpu')['optimizer'])\n",
    "\n",
    "\n",
    "# TEST LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model1.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in test_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model1.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model1_data_test = pd.DataFrame(features, index=names)\n",
    "model1_data_test['class'] = true_labels\n",
    "\n",
    "\n",
    "# TRAIN_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model1.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in train_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model1.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model1_data_train = pd.DataFrame(features, index=names)\n",
    "model1_data_train['class'] = true_labels\n",
    "        \n",
    "# VALID_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model1.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in valid_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model1.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "\n",
    "model1_data_valid = pd.DataFrame(features, index=names)\n",
    "model1_data_valid['class'] = true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66915e-c29e-4b9d-9206-f0ffa6f49ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data = pd.concat([model1_data_valid, model1_data_test, model1_data_train])\n",
    "full_data.to_csv('catboost_csv/model1_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dbee78-ba1f-4884-bbc6-23055dcc484d",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9b996-5fb8-414e-ac91-1c1f05e4e69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "device_sample = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model_sample = resnet50(weights=weights)\n",
    "\n",
    "for param in model_sample.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_sample.fc = nn.Linear(model_sample.fc.in_features, 100)\n",
    "\n",
    "model_sample.to(device_sample)\n",
    "\n",
    "transform_sample = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model2 = CNNClass(model=model_sample,\n",
    "                  transform=transform_sample,\n",
    "                  params=model_params,\n",
    "                  optimizer = optim.Adam(model_sample.parameters(), lr=0.0005),\n",
    "                  name='resnet50_native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c319c-a9e5-4689-bacb-5faedf79f392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.model.load_state_dict(torch.load(f'weights/{model2.name}/{model2.name}.pth', \n",
    "                                        map_location='cpu')['model'])\n",
    "model2.optimizer.load_state_dict(torch.load(f'weights/{model2.name}/{model2.name}.pth',\n",
    "                                            map_location='cpu')['optimizer'])\n",
    "\n",
    "\n",
    "# TEST LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model2.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in test_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model2.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model2_data_test = pd.DataFrame(features, index=names)\n",
    "model2_data_test['class'] = true_labels\n",
    "\n",
    "\n",
    "# TRAIN_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model2.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in train_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model2.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model2_data_train = pd.DataFrame(features, index=names)\n",
    "model2_data_train['class'] = true_labels\n",
    "        \n",
    "# VALID_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model2.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in valid_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model2.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "\n",
    "model2_data_valid = pd.DataFrame(features, index=names)\n",
    "model2_data_valid['class'] = true_labels\n",
    "\n",
    "full_data = pd.concat([model2_data_valid, model2_data_test, model2_data_train])\n",
    "full_data.to_csv('catboost_csv/model2_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ba5a8-4b42-4293-baee-1123da522e9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3fa96-404d-4da1-aff3-440ecdf3eb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "\n",
    "device_sample = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = Inception_V3_Weights.DEFAULT\n",
    "model_sample = inception_v3(weights=weights)\n",
    "\n",
    "for param in model_sample.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_sample.fc = nn.Linear(model_sample.fc.in_features,\n",
    "                      100)\n",
    "model_sample.aux_logits=False\n",
    "model_sample.to(device_sample)\n",
    "\n",
    "transform_sample = transforms.Compose([\n",
    "    transforms.Resize(299),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model3 = CNNClass(model=model_sample,\n",
    "                  transform=transform_sample,\n",
    "                  params=model_params,\n",
    "                  name='inception-v3_native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dcc86-ab8e-41c3-a0bf-4727f878bad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.model.load_state_dict(torch.load(f'weights/{model3.name}/{model3.name}.pth', \n",
    "                                        map_location='cpu')['model'])\n",
    "model3.optimizer.load_state_dict(torch.load(f'weights/{model3.name}/{model3.name}.pth',\n",
    "                                            map_location='cpu')['optimizer'])\n",
    "\n",
    "\n",
    "# TEST LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model3.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in test_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model3.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model3_data_test = pd.DataFrame(features, index=names)\n",
    "model3_data_test['class'] = true_labels\n",
    "\n",
    "\n",
    "# TRAIN_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model3.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in train_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model3.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model3_data_train = pd.DataFrame(features, index=names)\n",
    "model3_data_train['class'] = true_labels\n",
    "        \n",
    "# VALID_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model3.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in valid_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model3.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "\n",
    "model3_data_valid = pd.DataFrame(features, index=names)\n",
    "model3_data_valid['class'] = true_labels\n",
    "\n",
    "full_data = pd.concat([model3_data_valid, model3_data_test, model3_data_train])\n",
    "full_data.to_csv('catboost_csv/model3_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedade3-5f3f-4117-a2f5-0d4c31a4f893",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af81eb-c39d-410e-b7f0-935297991c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
    "\n",
    "device_sample = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = EfficientNet_B3_Weights.DEFAULT\n",
    "model_sample = efficientnet_b3(weights=weights)\n",
    "\n",
    "for param in model_sample.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_sample.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True),\n",
    "    nn.Linear(in_features=1536, out_features=100)\n",
    ")\n",
    "\n",
    "model_sample.to(device_sample)\n",
    "\n",
    "transform_sample = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model4 = CNNClass(model=model_sample,\n",
    "                  transform=transform_sample,\n",
    "                  params=model_params,\n",
    "                  optimizer = optim.Adam(model_sample.parameters(), lr=0.0005),\n",
    "                  name='efficientnet-b3_native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e5a46-b49b-441f-b403-e7019c77355c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model4.model.load_state_dict(torch.load(f'weights/{model4.name}/{model4.name}.pth', \n",
    "                                        map_location='cpu')['model'])\n",
    "model4.optimizer.load_state_dict(torch.load(f'weights/{model4.name}/{model4.name}.pth',\n",
    "                                            map_location='cpu')['optimizer'])\n",
    "\n",
    "\n",
    "# TEST LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model4.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in test_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model4.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model4_data_test = pd.DataFrame(features, index=names)\n",
    "model4_data_test['class'] = true_labels\n",
    "\n",
    "\n",
    "# TRAIN_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model4.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in train_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model4.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model4_data_train = pd.DataFrame(features, index=names)\n",
    "model4_data_train['class'] = true_labels\n",
    "        \n",
    "# VALID_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model4.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in valid_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model4.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "\n",
    "model4_data_valid = pd.DataFrame(features, index=names)\n",
    "model4_data_valid['class'] = true_labels\n",
    "\n",
    "full_data = pd.concat([model4_data_valid, model4_data_test, model4_data_train])\n",
    "full_data.to_csv('catboost_csv/model4_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f593de7-4985-4588-9bdf-49b18c745058",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171d459-52e0-4306-87dd-cf0fc711a7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "device_sample = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "model_sample = vit_b_16(weights=weights)\n",
    "\n",
    "for param in model_sample.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_sample.heads.head = nn.Linear(model_sample.heads.head.in_features, 100)\n",
    "\n",
    "model_sample.to(device_sample)\n",
    "\n",
    "transform_sample = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model5 = CNNClass(model=model_sample,\n",
    "                  transform=transform_sample,\n",
    "                  params=model_params,\n",
    "                  optimizer = optim.SGD(model_sample.parameters(), lr=0.001, momentum=0.9, weight_decay=0.03),\n",
    "                  name='vit-b-16_native')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90488c-57e3-4023-ad46-301a82b446f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model5.model.load_state_dict(torch.load(f'weights/{model5.name}/{model5.name}.pth', \n",
    "                                        map_location='cpu')['model'])\n",
    "model5.optimizer.load_state_dict(torch.load(f'weights/{model5.name}/{model5.name}.pth',\n",
    "                                            map_location='cpu')['optimizer'])\n",
    "\n",
    "\n",
    "# TEST LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model5.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in test_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model5.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model5_data_test = pd.DataFrame(features, index=names)\n",
    "model5_data_test['class'] = true_labels\n",
    "\n",
    "\n",
    "# TRAIN_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model5.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in train_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model5.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "        \n",
    "model5_data_train = pd.DataFrame(features, index=names)\n",
    "model5_data_train['class'] = true_labels\n",
    "        \n",
    "# VALID_LOADER\n",
    "features = []\n",
    "names = []\n",
    "true_labels = []\n",
    "\n",
    "model5.model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels, name in valid_loader:\n",
    "        y_true = int(labels.cpu().numpy())\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = model5.model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        features.append(outputs.data.cpu().numpy()[0])\n",
    "        names.append(name[0])\n",
    "        true_labels.append(y_true)\n",
    "\n",
    "model5_data_valid = pd.DataFrame(features, index=names)\n",
    "model5_data_valid['class'] = true_labels\n",
    "\n",
    "full_data = pd.concat([model5_data_valid, model5_data_test, model5_data_train])\n",
    "full_data.to_csv('catboost_csv/model5_outputs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5c927-417d-48b9-8e35-00a3c7152025",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "!python -m  pip install catboost-dev[widget]==1.2rc0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f38619-c525-4da4-92da-2ba7dbb6fb0b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Use Catboost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f5faa-4be8-4dd3-8635-f13972be8e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863fd3bb-f62c-474b-9f11-15003adc1c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob('catboost_csv/*')\n",
    "df_model1 = pd.read_csv(files[0])\n",
    "y = df_model1['class']\n",
    "df_model1 = df_model1.iloc[:,:-1]\n",
    "df_model1.columns = ['path'] + ['model1_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model2 = pd.read_csv(files[1])\n",
    "df_model2 = df_model2.iloc[:,:-1]\n",
    "df_model2.columns = ['path'] + ['model2_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model3 = pd.read_csv(files[2])\n",
    "df_model3 = df_model3.iloc[:,:-1]\n",
    "df_model3.columns = ['path'] + ['model3_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model4 = pd.read_csv(files[3])\n",
    "df_model4 = df_model4.iloc[:,:-1]\n",
    "df_model4.columns = ['path'] + ['model4_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model5 = pd.read_csv(files[4])\n",
    "df_model5 = df_model5.iloc[:,:-1]\n",
    "df_model5.columns = ['path'] + ['model5_'+str(i) for i in range (1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d578a90-df94-4318-a60f-05cbfda61ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_model1.merge(df_model2,\n",
    "                     on='path').merge(df_model3,\n",
    "                                      on='path').merge(df_model4,\n",
    "                                                       on='path').merge(df_model5,\n",
    "                                                                        on='path')\n",
    "\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4219515-a781-457a-8be9-ba387a6b8b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = df[df['path'].str.contains('train')].sample(frac = 1, random_state=11)\n",
    "valid = df[df['path'].str.contains('valid')].sample(frac = 1, random_state=11)\n",
    "test = df[df['path'].str.contains('test')].sample(frac = 1, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3558049-ec9c-412e-bdb6-be5fdea9b109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c5ecd-5cfe-4d17-910f-0db3c3bc07d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1:-1]\n",
    "y_train = train['y']\n",
    "\n",
    "X_test_initial = test.copy()\n",
    "X_test = test.iloc[:,1:-1]\n",
    "y_test = test['y']\n",
    "\n",
    "X_valid = valid.iloc[:,1:-1]\n",
    "y_valid = valid['y']\n",
    "\n",
    "y_test_initial = y_test.copy()\n",
    "\n",
    "y_train = np.squeeze(pd.get_dummies(y_train))\n",
    "y_valid = np.squeeze(pd.get_dummies(y_valid))\n",
    "y_test = np.squeeze(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960c2db-4e24-4f11-9a47-76892f81a1f5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## CATBOOST: Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102d800-3c74-4ba6-83d1-f9d9d3df4a06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fine? 100 epoches: 0.83\n",
    "clf1 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.8,\n",
    "                         max_depth=5, \n",
    "                         l2_leaf_reg=5,\n",
    "                         iterations=2000,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf1.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf1.save_model('catboost_fitted_1.cbm')\n",
    "\n",
    "y_pred = clf1.predict(X_test)\n",
    "with open(f'catboost_accuracy1.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d146f4-7da4-4d1f-ad84-8b2d7cedd717",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## CATBOOST: Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1e95f-f578-40bc-948f-85c00d744e2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf2 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.8,\n",
    "                         max_depth=5,\n",
    "                         l2_leaf_reg=10,\n",
    "                         iterations=2000,\n",
    "                         early_stopping_rounds=30,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf2.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf2.save_model('catboost_fitted_2.cbm')\n",
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "with open(f'catboost_accuracy2.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d2099-e27e-4f05-94e9-1e1ca59f4a8b",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## CATBOOST: Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e32054-711b-4def-85bb-f3c96899c34c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf3 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.8,\n",
    "                         max_depth=2,\n",
    "                         l2_leaf_reg=10,\n",
    "                         iterations=2000,\n",
    "                         early_stopping_rounds=30,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf3.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf3.save_model('catboost_fitted_3.cbm')\n",
    "\n",
    "y_pred = clf3.predict(X_test)\n",
    "with open(f'catboost_accuracy3.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53127f-93d2-4cb2-bfba-1a41e5dcbecb",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## CATBOOST: Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3f9d2-78c9-4c60-9f4b-fd684602690f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf4 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                          learning_rate=0.8,\n",
    "                          max_depth=2,\n",
    "                          l2_leaf_reg=15,\n",
    "                          iterations=2000,\n",
    "                          early_stopping_rounds=30,\n",
    "                          eval_metric='Accuracy',\n",
    "                          use_best_model=True)\n",
    "\n",
    "clf4.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf4.save_model('catboost_fitted_4.cbm')\n",
    "\n",
    "y_pred = clf4.predict(X_test)\n",
    "with open(f'catboost_accuracy4.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182279c8-c635-4bef-8e46-d76b48190c3d",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## CATBOOST: Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f496eb2-1f4d-45c5-b3ba-c2938deebede",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf5 = CatBoostClassifier(loss_function='MultiLogloss', \n",
    "                          learning_rate=0.8,\n",
    "                          depth=5,\n",
    "                          l2_leaf_reg=15,\n",
    "                          iterations=2000,\n",
    "                          early_stopping_rounds=30,\n",
    "                          eval_metric='Accuracy',\n",
    "                          use_best_model=True)\n",
    "\n",
    "clf5.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf5.save_model('catboost_fitted_5.cbm')\n",
    "\n",
    "y_pred = clf5.predict(X_test)\n",
    "with open(f'catboost_accuracy5.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c95fd8-b50d-48f1-bcd6-7fad3c60a33a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Evaluate Perfomance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07159349-3ccd-4456-8843-416c9682fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.load_model('catboost_with_air-hockey/catboost_fitted_1.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2a655-a428-4541-b71a-13cee2f0ad11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_for_confustion = X_test_initial[['path', 'y']]\n",
    "\n",
    "y_pred = pd.DataFrame(clf1.predict(X_test_initial.iloc[:,1:-1])).idxmax(axis=1)\n",
    "\n",
    "X_test_for_confustion['y_pred'] = y_pred.to_list()\n",
    "\n",
    "classes = X_test_for_confustion['path'].str.split('/').str[-2]\n",
    "ys = X_test_for_confustion['y']\n",
    "\n",
    "mapper = pd.concat([classes, ys], axis=1).drop_duplicates()\n",
    "mapper = mapper.set_index('y')['path'].to_dict()\n",
    "\n",
    "X_test_for_confustion['y'] = X_test_for_confustion['y'].map(mapper)\n",
    "X_test_for_confustion['y_pred'] = X_test_for_confustion['y_pred'].map(mapper)\n",
    "\n",
    "X_test_for_confustion[X_test_for_confustion['y'] != X_test_for_confustion['y_pred']]['y_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c63dc5-6032-4bdf-8c2b-cff44f2897b5",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Again catboost, but let's drop air hockey class and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b72feb-0f48-45a3-90dd-afe8342c5547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c23d4-2eb9-45b8-8837-2f3ee4a8febf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = glob.glob('catboost_csv/*')\n",
    "df_model1 = pd.read_csv(files[0])\n",
    "y = df_model1['class']\n",
    "df_model1 = df_model1.iloc[:,:-1]\n",
    "df_model1.columns = ['path'] + ['model1_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model2 = pd.read_csv(files[1])\n",
    "df_model2 = df_model2.iloc[:,:-1]\n",
    "df_model2.columns = ['path'] + ['model2_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model3 = pd.read_csv(files[2])\n",
    "df_model3 = df_model3.iloc[:,:-1]\n",
    "df_model3.columns = ['path'] + ['model3_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model4 = pd.read_csv(files[3])\n",
    "df_model4 = df_model4.iloc[:,:-1]\n",
    "df_model4.columns = ['path'] + ['model4_'+str(i) for i in range (1, 101)]\n",
    "\n",
    "df_model5 = pd.read_csv(files[4])\n",
    "df_model5 = df_model5.iloc[:,:-1]\n",
    "df_model5.columns = ['path'] + ['model5_'+str(i) for i in range (1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd0b96c-3bee-47bb-8ea3-5db068258138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_model1.merge(df_model2,\n",
    "                     on='path').merge(df_model3,\n",
    "                                      on='path').merge(df_model4,\n",
    "                                                       on='path').merge(df_model5,\n",
    "                                                                        on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ab063-3757-4c09-a3ac-de10f617cf44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[~(df['path'].str.contains('.ipynb') | df['path'].str.contains('air hockey'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696e410-1cdd-4116-8c51-ae42e4047580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bc360-def4-4877-834e-16726b816719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = df[df['path'].str.contains('train')].sample(frac = 1, random_state=11)\n",
    "valid = df[df['path'].str.contains('valid')].sample(frac = 1, random_state=11)\n",
    "test = df[df['path'].str.contains('test')].sample(frac = 1, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50187ce5-8ce7-4b8b-b0fc-6a665c3bc788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bca096-f306-44f1-937c-113d6623f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1:-1]\n",
    "y_train = train['y']\n",
    "\n",
    "X_test_initial = test.copy()\n",
    "X_test = test.iloc[:,1:-1]\n",
    "y_test = test['y']\n",
    "\n",
    "X_valid = valid.iloc[:,1:-1]\n",
    "y_valid = valid['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f59d3-d753-4304-8b90-0c1c2b81071e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_initial = y_test.copy()\n",
    "\n",
    "y_train = np.squeeze(pd.get_dummies(y_train))\n",
    "y_valid = np.squeeze(pd.get_dummies(y_valid))\n",
    "y_test = np.squeeze(pd.get_dummies(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22563a2-eaed-4d7a-9d6b-ede0425e3454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf1 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.7, \n",
    "                         l2_leaf_reg=25,\n",
    "                          depth=5,\n",
    "                          early_stopping_rounds=50,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf1.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf1.save_model('catboost_fitted_1.cbm')\n",
    "\n",
    "y_pred = clf1.predict(X_test)\n",
    "with open(f'catboost_accuracy1.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae8adb-ee56-44e0-97a8-9598470ce33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf2 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.65, \n",
    "                         l2_leaf_reg=15,\n",
    "                          depth=4,\n",
    "                          early_stopping_rounds=50,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf2.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf2.save_model('catboost_fitted_2.cbm')\n",
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "with open(f'catboost_accuracy2.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b823c-c107-4f13-89b6-5439d566bb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf3 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.6, \n",
    "                         l2_leaf_reg=10,\n",
    "                          depth=4,\n",
    "                          early_stopping_rounds=50,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf3.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf3.save_model('catboost_fitted_3.cbm')\n",
    "\n",
    "y_pred = clf3.predict(X_test)\n",
    "with open(f'catboost_accuracy3.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830b377-f45e-4398-9e8b-5c5d8d181a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf4 = CatBoostClassifier(loss_function='MultiCrossEntropy', \n",
    "                         learning_rate=0.55, \n",
    "                         l2_leaf_reg=35,\n",
    "                          depth=4,\n",
    "                          early_stopping_rounds=50,\n",
    "                         eval_metric='Accuracy',\n",
    "                         use_best_model=True)\n",
    "\n",
    "clf4.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose_eval=True)\n",
    "clf4.save_model('catboost_fitted_4.cbm')\n",
    "\n",
    "y_pred = clf4.predict(X_test)\n",
    "with open(f'catboost_accuracy4.csv', 'w') as f:\n",
    "    f.write(str(accuracy_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
